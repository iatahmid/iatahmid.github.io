---
title: "Evaluating the Feasibility of Predicting Information Relevance During Sensemaking with Eye Gaze Data"
collection: publications
category: semantic
permalink: /publication/2025-03-24-eyest-recommendations
excerpt: 'Sensemaking is a complex task that places a heavy cognitive demand on individuals. With the recent surge in data availability, making sense of vast amounts of information has become a significant challenge for many professionals, such as intelligence analysts.  Immersive technologies such as mixed reality offer a potential solution by providing virtually unlimited space to organize data. However, the difficulty of processing, filtering relevant information, and synthesizing insights remains. We proposed using eye-tracking data from mixed reality head-worn displays to derive the analyst's perceived interest in documents and words, and convey that part of the mental model to the analyst. The global interest of the documents is reflected in their color, and their order on the list, while the local interest of the documents is used to generate focused recommendations for a document. To evaluate these recommendation cues, we conducted a user study with two conditions. A gaze-aware system, EyeST, and a Freestyle system without gaze-based visual cues. Our findings reveal that the EyeST helped analysts stay on track by reading more essential information while avoiding distractions.  However, this came at the cost of reduced focused attention and perceived system performance. The results of our study highlight the need for explainable AI in human-AI collaborative sensemaking to build user trust and encourage the integration of AI outputs into the immersive sensemaking process.  Based on our findings, we offer a set of guidelines for designing gaze-driven recommendation cues in an immersive environment.'
date: 2025-03-24
venue: ''
teaser: '/images/teasers/eyest_recommendations_teaser.jpg'
slidesurl: ''
prototypeurl: ''
paperurl: ''
citation: ''
---

The advancements in AI have raised intriguing possibilities for personalized experiences. 
Imagine if AI could anticipate your interests by analyzing your gaze patterns from the last hour of reading. What if it could recommend insights not just based on the pages you visited but on the specific parts of those pages that held your attention? The concept extends into immersive spaces. 
In XR, even though you get more space to organize massive amounts of information, you’d still have to exhaustively go through all that information to make any sense. The challenge persists. Could a gaze-driven intelligent system alleviate this by providing personalized context as you navigate the data?

The answer is a resounding yes!

However, the key to such human-AI collaboration lies in user acceptance. Our research underscores that regardless of AI sophistication, trust and effectiveness hinge on context. 
Explainability and transparency are pivotal; users must comprehend not just the AI’s actions, but also the rationale behind its recommendations. Without these elements, even the most intelligent systems may fall short.

So, what should we keep in mind for AI-mediated sensemaking in the immersive space? Read our paper to know more! (link to be added later)

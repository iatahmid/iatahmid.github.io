---
title: "Enhancing Immersive Sensemaking with Gaze-Driven Smart Recommendations"
collection: publications
category: semantic
permalink: /publication/2025-03-24-eyest-recommendations
excerpt: 'Sensemaking is a complex task that places a heavy cognitive demand on individuals. With the recent surge in data availability,
making sense of vast amounts of information has become a significant challenge for many professionals, such as intelligence analysts.
Immersive technologies such as mixed reality offer a potential solution by providing virtually unlimited space to organize data. However,
the difficulty of processing, filtering relevant information, and synthesizing insights remains. We proposed using eye-tracking data
from mixed reality head-worn displays to derive the analyst’s perceived interest in documents and words, and convey that part of the
mental model to the analyst. The global interest of the documents is reflected in their color, and their order on the list, while the local
interest of the documents is used to generate focused recommendations for a document. To evaluate these recommendation cues, we
conducted a user study with two conditions. A gaze-aware system, EyeST, and a Freestyle system without gaze-based visual cues.
Our findings reveal that the EyeST helped analysts stay on track by reading more essential information while avoiding distractions.
However, this came at the cost of reduced focused attention and perceived system performance. The results of our study highlight the
need for explainable AI in human-AI collaborative sensemaking to build user trust and encourage the integration of AI outputs into
the immersive sensemaking process. Based on our findings, we offer a set of guidelines for designing gaze-driven recommendation
cues in an immersive environment.'
date: 2025-03-24
venue: '30th Annual ACM Conference on Intelligent User Interface (IUI)'
teaser: '/images/teasers/eyest_recommendations_teaser.jpg'
slidesurl: ''
prototypeurl: 'https://youtu.be/fc9HAB93rNA?si=erfqStrGFtp2O5lo'
paperurl: 'https://dl.acm.org/doi/full/10.1145/3708359.3712103'
citation: 'Tahmid, I. A., North, C., Davidson, K., Whitley, K., & Bowman, D. A. (2025, March). <em>Enhancing Immersive Sensemaking with Gaze-Driven Smart Recommendations</em>. In 2025 ACM Intelligent User Intefaces (IUI). ACM.'
---

The advancements in AI have raised intriguing possibilities for personalized experiences. 
Imagine if AI could anticipate your interests by analyzing your gaze patterns from the last hour of reading. What if it could recommend insights not just based on the pages you visited but on the specific parts of those pages that held your attention? The concept extends into immersive spaces. 
In XR, even though you get more space to organize massive amounts of information, you’d still have to exhaustively go through all that information to make any sense. The challenge persists. Could a gaze-driven intelligent system alleviate this by providing personalized context as you navigate the data?

The answer is a resounding yes!

However, the key to such human-AI collaboration lies in user acceptance. Our research underscores that regardless of AI sophistication, trust and effectiveness hinge on context. 
Explainability and transparency are pivotal; users must comprehend not just the AI’s actions, but also the rationale behind its recommendations. Without these elements, even the most intelligent systems may fall short.

So, what should we keep in mind for AI-mediated sensemaking in the immersive space? Read our paper to know more! 

Paper Link: https://dl.acm.org/doi/full/10.1145/3708359.3712103
Demo Link: https://youtu.be/fc9HAB93rNA?si=erfqStrGFtp2O5lo

---
title: "Evaluating the Feasibility of Predicting Information Relevance During Sensemaking with Eye Gaze Data"
collection: publications
category: semantic
permalink: /publication/2025-03-24-eyest-recommendations
excerpt: 'Eye gaze patterns vary based on reading purpose and complexity, and can provide insights into a reader’s perception of the content. We hypothesize that during a complex sensemaking task with many text-based documents, we will be able to use eye-tracking data to predict the importance of documents and words, which could be the basis for intelligent suggestions made by the system to an analyst. We introduce a novel eye-gaze metric called ‘GazeScore’ that predicts an analyst’s perception of the relevance of each document and word when they perform a sensemaking task. We conducted a user study to assess the effectiveness of this metric and found strong evidence that documents and words with high GazeScores are perceived as more relevant, while those with low GazeScores were considered less relevant. We explore potential real-time applications of this metric to facilitate immersive sensemaking tasks by offering relevant suggestions.'
date: 2025-03-24
venue: 'test'
teaser: '/images/teasers/eyest_recommendations_teaser.jpg'
slidesurl: 'https://docs.google.com/presentation/d/1SoxcmTTrjdMMXQgRrwcDIOEG4CSFqZkd'
prototypeurl: 'https://youtu.be/6gAcD0t01y0'
paperurl: 'https://iatahmid.github.io/files/ismar23-eyest.pdf'
citation: 'Tahmid, I. A., Lisle, L., Davidson, K., Whitley, K., North, C., & Bowman, D. A. (2023, October). <em>Evaluating the Feasibility of Predicting Information Relevance During Sensemaking with Eye Gaze Data</em>. In 2023 IEEE International Symposium on Mixed and Augmented Reality (ISMAR) (pp. 713-722). IEEE.'
---

The advancements in AI have raised intriguing possibilities for personalized experiences. 
Imagine if AI could anticipate your interests by analyzing your gaze patterns from the last hour of reading. What if it could recommend insights not just based on the pages you visited but on the specific parts of those pages that held your attention? The concept extends into immersive spaces. 
In XR, even though you get more space to organize massive amounts of information, you’d still have to exhaustively go through all that information to make any sense. The challenge persists. Could a gaze-driven intelligent system alleviate this by providing personalized context as you navigate the data?

The answer is a resounding yes!

However, the key to such human-AI collaboration lies in user acceptance. Our research underscores that regardless of AI sophistication, trust and effectiveness hinge on context. 
Explainability and transparency are pivotal; users must comprehend not just the AI’s actions, but also the rationale behind its recommendations. Without these elements, even the most intelligent systems may fall short.

So, what should we keep in mind for AI-mediated sensemaking in the immersive space? Read our paper to know more! (link to be added later)
